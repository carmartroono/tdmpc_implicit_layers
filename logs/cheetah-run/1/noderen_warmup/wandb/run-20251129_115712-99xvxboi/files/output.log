Logs will be synced with wandb.
Architecture: TD-MPC2 World Model
Encoder: ModuleDict(
  (state): DEQ_MLP(
    (act): GELU(approximate='none')
    (input_proj): Sequential(
      (0): Linear(in_features=17, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): GELU(approximate='none')
    )
    (deq_func): DEQFunc(
      (layers): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): GELU(approximate='none')
        (3): Dropout(p=0.05, inplace=False)
        (4): Linear(in_features=256, out_features=256, bias=True)
        (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (6): GELU(approximate='none')
      )
    )
    (output_proj): Sequential(
      (0): Linear(in_features=256, out_features=512, bias=True)
      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (skip_proj): Linear(in_features=17, out_features=512, bias=True)
    (deq): DEQSliced()
  )
)
Dynamics: NODE_REN(
  (sys): _System_contractive(
    (act): Tanh()
  )
)
Reward: Sequential(
  (0): NormedLinear(in_features=518, out_features=512, bias=True, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): Linear(in_features=512, out_features=101, bias=True)
)
Policy prior: Sequential(
  (0): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): Linear(in_features=512, out_features=12, bias=True)
)
Q-functions: Vectorized 5x Sequential(
  (0): NormedLinear(in_features=518, out_features=512, bias=True, dropout=0.01, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): Linear(in_features=512, out_features=101, bias=True)
)
Learnable parameters: 5,378,788
Buffer capacity: 400,000
Storage required: 0.04 GB
Using CUDA:0 memory for storage.
Pretraining agent on seed data...
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/lug15gew/Desktop/thesis/popec/train.py", line 70, in <module>
    train()
  File "/home/lug15gew/Desktop/thesis/.venv/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/lug15gew/Desktop/thesis/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/lug15gew/Desktop/thesis/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/lug15gew/Desktop/thesis/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/home/lug15gew/Desktop/thesis/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/lug15gew/Desktop/thesis/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/lug15gew/Desktop/thesis/.venv/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/home/lug15gew/Desktop/thesis/.venv/lib/python3.12/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/home/lug15gew/Desktop/thesis/.venv/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lug15gew/Desktop/thesis/popec/train.py", line 65, in train
    trainer.train()
  File "/home/lug15gew/Desktop/thesis/popec/trainer/online_trainer.py", line 122, in train
    _train_metrics = self.agent.update(self.buffer)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lug15gew/Desktop/thesis/popec/tdmpc2.py", line 361, in update
    return self._update(obs, action, reward, terminated, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lug15gew/Desktop/thesis/popec/tdmpc2.py", line 344, in _update
    return info.detach().mean()
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/lug15gew/Desktop/thesis/.venv/lib64/python3.12/site-packages/tensordict/base.py", line 1501, in mean
    return self._cast_reduction(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/lug15gew/Desktop/thesis/.venv/lib64/python3.12/site-packages/tensordict/_td.py", line 1138, in _cast_reduction
    return self._fast_apply(
           ^^^^^^^^^^^^^^^^^
  File "/home/lug15gew/Desktop/thesis/.venv/lib64/python3.12/site-packages/tensordict/base.py", line 9398, in _fast_apply
    result = func(
             ^^^^^
  File "/home/lug15gew/Desktop/thesis/.venv/lib64/python3.12/site-packages/tensordict/_td.py", line 1473, in _apply_nest
    item_trsf = fn(item, *_others)
                ^^^^^^^^^^^^^^^^^^
  File "/home/lug15gew/Desktop/thesis/.venv/lib64/python3.12/site-packages/tensordict/_td.py", line 1136, in reduction
    return getattr(val, reduction_name)(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long
