Logs will be synced with wandb.
Architecture: TD-MPC2 World Model
Encoder: ModuleDict(
  (state): DEQ_MLP(
    (act): GELU(approximate='none')
    (input_proj): Sequential(
      (0): Linear(in_features=17, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): GELU(approximate='none')
    )
    (deq_func): DEQFunc(
      (layers): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): GELU(approximate='none')
        (3): Dropout(p=0.05, inplace=False)
        (4): Linear(in_features=256, out_features=256, bias=True)
        (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (6): GELU(approximate='none')
      )
    )
    (output_proj): Sequential(
      (0): Linear(in_features=256, out_features=512, bias=True)
      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (skip_proj): Linear(in_features=17, out_features=512, bias=True)
    (deq): DEQSliced()
  )
)
Dynamics: NODE_REN(
  (sys): _System_contractive(
    (act): Tanh()
  )
)
Reward: Sequential(
  (0): NormedLinear(in_features=518, out_features=512, bias=True, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): Linear(in_features=512, out_features=101, bias=True)
)
Policy prior: Sequential(
  (0): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): Linear(in_features=512, out_features=12, bias=True)
)
Q-functions: Vectorized 5x Sequential(
  (0): NormedLinear(in_features=518, out_features=512, bias=True, dropout=0.01, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): Linear(in_features=512, out_features=101, bias=True)
)
Learnable parameters: 5,429,068
